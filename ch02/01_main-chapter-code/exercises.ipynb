{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.343777Z",
     "start_time": "2025-03-14T04:54:01.335180Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.2\n",
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exercise #2.1\n",
   "id": "f939c0a559a52cc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.371772Z",
     "start_time": "2025-03-14T04:54:01.367859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ],
   "id": "177cb70959cbed29",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.403173Z",
     "start_time": "2025-03-14T04:54:01.398195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ints = tokenizer.encode(\"Akwirw ier\")\n",
    "print(ints)"
   ],
   "id": "ac8543bb73c0dd56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.454872Z",
     "start_time": "2025-03-14T04:54:01.449740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in ints:\n",
    "    print(f\"{i}: {tokenizer.decode([i])}\")"
   ],
   "id": "ba1501e7d867d5ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33901: Ak\n",
      "86: w\n",
      "343: ir\n",
      "86: w\n",
      "220:  \n",
      "959: ier\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.517181Z",
     "start_time": "2025-03-14T04:54:01.511038Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"Ak\")",
   "id": "be09809e0e62f3c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.564461Z",
     "start_time": "2025-03-14T04:54:01.559340Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"w\")",
   "id": "542c3850363342e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.595464Z",
     "start_time": "2025-03-14T04:54:01.590983Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"ir\")",
   "id": "af127d91518792d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[343]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.626261Z",
     "start_time": "2025-03-14T04:54:01.621325Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"w\")",
   "id": "ff1525c423b8d5e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.660582Z",
     "start_time": "2025-03-14T04:54:01.656094Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\" \")",
   "id": "d02715371206b051",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.695556Z",
     "start_time": "2025-03-14T04:54:01.690891Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"ier\")",
   "id": "684a08132a7ac329",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[959]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.753447Z",
     "start_time": "2025-03-14T04:54:01.749330Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode([33901,86,343,86,220,959])",
   "id": "2c34cbaf38eca401",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akwirw ier'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exercise #2.2",
   "id": "32dfe6ceeccc5513"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.797691Z",
     "start_time": "2025-03-14T04:54:01.793983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "cf632f54f3bd2f3b",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.839722Z",
     "start_time": "2025-03-14T04:54:01.834368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.input_ids[idx],self.target_ids[idx])\n"
   ],
   "id": "916af3b18f4f6f26",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.956015Z",
     "start_time": "2025-03-14T04:54:01.876922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader(txt,batch_size=4,max_length=256,stride=128):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = DatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "with open(\"/Users/chanhpham/PycharmProjects/LLMs-from-scratch/ch02/01_main-chapter-code/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    raw_txt = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded_txt = tokenizer.encode(raw_txt)\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "max_len = 4\n",
    "context_length = max_len\n",
    "\n",
    "token_embedding = torch.nn.Embedding(context_length,output_dim)\n",
    "position_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
   ],
   "id": "aacbe8cf87386b9c",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:02.070995Z",
     "start_time": "2025-03-14T04:54:01.963547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader(raw_txt,batch_size=4,max_length=2,stride=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x,y = batch\n",
    "\n",
    "x"
   ],
   "id": "d4d7b5d64fa4a88c",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[184]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m dataloader = create_dataloader(raw_txt,batch_size=\u001B[32m4\u001B[39m,max_length=\u001B[32m2\u001B[39m,stride=\u001B[32m2\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\n\u001B[32m      6\u001B[39m x\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    628\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    629\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    630\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m631\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    632\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    633\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[32m    634\u001B[39m         \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[32m    635\u001B[39m         \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    673\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m674\u001B[39m     index = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    675\u001B[39m     data = \u001B[38;5;28mself\u001B[39m._dataset_fetcher.fetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    676\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:621\u001B[39m, in \u001B[36m_BaseDataLoaderIter._next_index\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    620\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_index\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m621\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m._sampler_iter)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/utils/data/sampler.py:287\u001B[39m, in \u001B[36mBatchSampler.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    285\u001B[39m batch = [\u001B[32m0\u001B[39m] * \u001B[38;5;28mself\u001B[39m.batch_size\n\u001B[32m    286\u001B[39m idx_in_batch = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m287\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msampler\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    288\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx_in_batch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\n\u001B[32m    289\u001B[39m \u001B[43m    \u001B[49m\u001B[43midx_in_batch\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/LLMs-from-scratch/.venv/lib/python3.11/site-packages/torch/utils/data/sampler.py:111\u001B[39m, in \u001B[36mSequentialSampler.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    110\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Iterator[\u001B[38;5;28mint\u001B[39m]:\n\u001B[32m--> \u001B[39m\u001B[32m111\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m.data_source)))\n",
      "\u001B[31mTypeError\u001B[39m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataloader = create_dataloader(raw_txt,batch_size=4,max_length=8,stride=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x,y = batch\n",
    "\n",
    "x"
   ],
   "id": "c0a3aadf32d9934d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
