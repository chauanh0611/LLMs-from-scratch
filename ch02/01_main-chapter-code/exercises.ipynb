{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T12:27:54.548543Z",
     "start_time": "2025-03-14T12:27:54.534177Z"
    }
   },
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.2\n",
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exercise #2.1\n",
   "id": "f939c0a559a52cc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.371772Z",
     "start_time": "2025-03-14T04:54:01.367859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ],
   "id": "177cb70959cbed29",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.403173Z",
     "start_time": "2025-03-14T04:54:01.398195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ints = tokenizer.encode(\"Akwirw ier\")\n",
    "print(ints)"
   ],
   "id": "ac8543bb73c0dd56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.454872Z",
     "start_time": "2025-03-14T04:54:01.449740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in ints:\n",
    "    print(f\"{i}: {tokenizer.decode([i])}\")"
   ],
   "id": "ba1501e7d867d5ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33901: Ak\n",
      "86: w\n",
      "343: ir\n",
      "86: w\n",
      "220:  \n",
      "959: ier\n"
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.517181Z",
     "start_time": "2025-03-14T04:54:01.511038Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"Ak\")",
   "id": "be09809e0e62f3c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.564461Z",
     "start_time": "2025-03-14T04:54:01.559340Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"w\")",
   "id": "542c3850363342e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.595464Z",
     "start_time": "2025-03-14T04:54:01.590983Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"ir\")",
   "id": "af127d91518792d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[343]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.626261Z",
     "start_time": "2025-03-14T04:54:01.621325Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"w\")",
   "id": "ff1525c423b8d5e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[86]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.660582Z",
     "start_time": "2025-03-14T04:54:01.656094Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\" \")",
   "id": "d02715371206b051",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[220]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.695556Z",
     "start_time": "2025-03-14T04:54:01.690891Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.encode(\"ier\")",
   "id": "684a08132a7ac329",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[959]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T04:54:01.753447Z",
     "start_time": "2025-03-14T04:54:01.749330Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode([33901,86,343,86,220,959])",
   "id": "2c34cbaf38eca401",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akwirw ier'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Exercise #2.2",
   "id": "32dfe6ceeccc5513"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T12:27:42.039942Z",
     "start_time": "2025-03-14T12:27:42.003267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "id": "cf632f54f3bd2f3b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T12:27:43.719744Z",
     "start_time": "2025-03-14T12:27:43.707512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.input_ids[idx],self.target_ids[idx])\n"
   ],
   "id": "916af3b18f4f6f26",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T12:27:46.489023Z",
     "start_time": "2025-03-14T12:27:46.067887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataloader(txt,batch_size=4,max_length=256,stride=128):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = DatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "with open(\"/Users/chanhpham/PycharmProjects/LLMs-from-scratch/ch02/01_main-chapter-code/the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    raw_txt = f.read()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded_txt = tokenizer.encode(raw_txt)\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "max_len = 4\n",
    "context_length = max_len\n",
    "\n",
    "token_embedding = torch.nn.Embedding(context_length,output_dim)\n",
    "position_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
   ],
   "id": "aacbe8cf87386b9c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T12:27:49.988368Z",
     "start_time": "2025-03-14T12:27:49.471494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = create_dataloader(raw_txt,batch_size=4,max_length=2,stride=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x,y = batch\n",
    "\n",
    "x"
   ],
   "id": "d4d7b5d64fa4a88c",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m create_dataloader(raw_txt,batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m      4\u001B[0m     x,y \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m      6\u001B[0m x\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:621\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter._next_index\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_index\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampler_iter\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/sampler.py:287\u001B[0m, in \u001B[0;36mBatchSampler.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    285\u001B[0m batch \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size\n\u001B[1;32m    286\u001B[0m idx_in_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 287\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler:\n\u001B[1;32m    288\u001B[0m     batch[idx_in_batch] \u001B[38;5;241m=\u001B[39m idx\n\u001B[1;32m    289\u001B[0m     idx_in_batch \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/sampler.py:111\u001B[0m, in \u001B[0;36mSequentialSampler.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mint\u001B[39m]:\n\u001B[0;32m--> 111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_source\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[0;31mTypeError\u001B[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataloader = create_dataloader(raw_txt,batch_size=4,max_length=8,stride=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    x,y = batch\n",
    "\n",
    "x"
   ],
   "id": "c0a3aadf32d9934d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
